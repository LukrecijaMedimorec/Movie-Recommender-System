{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import heapq\n",
    "import random\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('./data/preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>poster_path</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>preprocessed_description</th>\n",
       "      <th>weighted_rating</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adventure Fantasy Family</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>104.0</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>Roll the dice and unleash the excitement!When ...</td>\n",
       "      <td>board game, disappearance, based on children's...</td>\n",
       "      <td>roll dice unleash excitement sibling judy pete...</td>\n",
       "      <td>6.867230</td>\n",
       "      <td>adventure fantasy family roll dice unleash exc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Romance Comedy</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>fishing, best friend, duringcreditsstinger, ol...</td>\n",
       "      <td>still yelling still fighting still ready famil...</td>\n",
       "      <td>6.170573</td>\n",
       "      <td>romance comedy still yelling still fighting st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy Drama Romance</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>/16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>based on novel, interracial relationship, sing...</td>\n",
       "      <td>friend people let never let forget mistreated ...</td>\n",
       "      <td>5.856086</td>\n",
       "      <td>comedy drama romance friend people let never l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>/e64sOI48hQXyru7naBFyssKFxVd.jpg</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>106.0</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>baby, midlife crisis, confidence, aging, daugh...</td>\n",
       "      <td>world back normal surprise life george bank re...</td>\n",
       "      <td>5.710835</td>\n",
       "      <td>comedy world back normal surprise life george ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action Crime Drama Thriller</td>\n",
       "      <td>949</td>\n",
       "      <td>tt0113277</td>\n",
       "      <td>/zMyfPUelumio3tiDKPffaUpsQTD.jpg</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Heat</td>\n",
       "      <td>A Los Angeles Crime SagaObsessive master thief...</td>\n",
       "      <td>robbery, detective, bank, obsession, chase, sh...</td>\n",
       "      <td>los angeles crime sagaobsessive master thief n...</td>\n",
       "      <td>7.629771</td>\n",
       "      <td>action crime drama thriller los angeles crime ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        genres     id    imdb_id  \\\n",
       "0     Adventure Fantasy Family   8844  tt0113497   \n",
       "1               Romance Comedy  15602  tt0113228   \n",
       "2         Comedy Drama Romance  31357  tt0114885   \n",
       "3                       Comedy  11862  tt0113041   \n",
       "4  Action Crime Drama Thriller    949  tt0113277   \n",
       "\n",
       "                        poster_path release_date  runtime  \\\n",
       "0  /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg   1995-12-15    104.0   \n",
       "1  /6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg   1995-12-22    101.0   \n",
       "2  /16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg   1995-12-22    127.0   \n",
       "3  /e64sOI48hQXyru7naBFyssKFxVd.jpg   1995-02-10    106.0   \n",
       "4  /zMyfPUelumio3tiDKPffaUpsQTD.jpg   1995-12-15    170.0   \n",
       "\n",
       "                         title  \\\n",
       "0                      Jumanji   \n",
       "1             Grumpier Old Men   \n",
       "2            Waiting to Exhale   \n",
       "3  Father of the Bride Part II   \n",
       "4                         Heat   \n",
       "\n",
       "                                         description  \\\n",
       "0  Roll the dice and unleash the excitement!When ...   \n",
       "1  Still Yelling. Still Fighting. Still Ready for...   \n",
       "2  Friends are the people who let you be yourself...   \n",
       "3  Just When His World Is Back To Normal... He's ...   \n",
       "4  A Los Angeles Crime SagaObsessive master thief...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  board game, disappearance, based on children's...   \n",
       "1  fishing, best friend, duringcreditsstinger, ol...   \n",
       "2  based on novel, interracial relationship, sing...   \n",
       "3  baby, midlife crisis, confidence, aging, daugh...   \n",
       "4  robbery, detective, bank, obsession, chase, sh...   \n",
       "\n",
       "                            preprocessed_description  weighted_rating  \\\n",
       "0  roll dice unleash excitement sibling judy pete...         6.867230   \n",
       "1  still yelling still fighting still ready famil...         6.170573   \n",
       "2  friend people let never let forget mistreated ...         5.856086   \n",
       "3  world back normal surprise life george bank re...         5.710835   \n",
       "4  los angeles crime sagaobsessive master thief n...         7.629771   \n",
       "\n",
       "                                            features  \n",
       "0  adventure fantasy family roll dice unleash exc...  \n",
       "1  romance comedy still yelling still fighting st...  \n",
       "2  comedy drama romance friend people let never l...  \n",
       "3  comedy world back normal surprise life george ...  \n",
       "4  action crime drama thriller los angeles crime ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20392"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = movies.drop_duplicates(subset=['id'])\n",
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('./data/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, min_df=0.05)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies['features']).astype(np.float32)\n",
    "cosine_similarities = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20392, 20392)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    def __init__(self, movie_ids, cosine_similarities):\n",
    "        self.movie_ids = list(set(movie_ids))\n",
    "        self.cosine_similarities = cosine_similarities\n",
    "\n",
    "    def get_content_based_recommendations(self, liked_movie_ids, disliked_movie_ids):\n",
    "        if not disliked_movie_ids:\n",
    "            seen_movies = liked_movie_ids\n",
    "        else:\n",
    "            seen_movies = liked_movie_ids + disliked_movie_ids\n",
    "\n",
    "        liked_movies_indices = [self.movie_ids.index(movie_id) for movie_id in liked_movie_ids]\n",
    "\n",
    "        all_recommendations = []\n",
    "\n",
    "        N = 10\n",
    "\n",
    "        for index in liked_movies_indices:\n",
    "            similarity_scores = self.cosine_similarities[index]\n",
    "            valid_top_indices = [i for i in heapq.nlargest(N, range(len(similarity_scores)), key=similarity_scores.__getitem__) if i != index and similarity_scores[i] != 1.0]\n",
    "            all_recommendations.extend(valid_top_indices)\n",
    "\n",
    "        random_10_recommendations = random.sample(all_recommendations, N)\n",
    "        \n",
    "        recommended_movie_ids = [self.movie_ids[index] for index in random_10_recommendations]\n",
    "\n",
    "        return recommended_movie_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30307, 211166, 41417, 18764, 43795, 38662, 324245, 44629, 212747, 53010]\n"
     ]
    }
   ],
   "source": [
    "liked_movie_ids = [13, 12, 24, 65, 127380] \n",
    "disliked_movie_ids = [74, 87, 137, 15854, 28368, 11778] \n",
    "content_based_recommender = ContentBasedRecommender(movie_ids=movies['id'], cosine_similarities=cosine_similarities)\n",
    "recommendations = content_based_recommender.get_content_based_recommendations(liked_movie_ids, disliked_movie_ids)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Penny Serenade', 'Firestorm', 'Twin Dragons', 'The Devil Commands', 'The Hurricane Express', 'Animal Kingdom', '7 Chinese Brothers', 'Rio, I Love You', 'La Chance de ma vie', 'All the Wrong Reasons']\n"
     ]
    }
   ],
   "source": [
    "recommended_movie_titles = movies[movies['id'].isin(recommendations)]['title'].tolist()\n",
    "print(recommended_movie_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommender(recommender, user_ratings_df, liked_movies_per_user=3, disliked_movies_per_user=3, num_recommendations=5):\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    user_metrics = {} \n",
    "\n",
    "    for user_id in user_ratings_df['userId'].unique():\n",
    "        \n",
    "        user_ratings = user_ratings_df[user_ratings_df['userId'] == user_id]\n",
    "        liked_movies = user_ratings[user_ratings['binary_rating'] == 1]['movieId'].tolist()\n",
    "        disliked_movies = user_ratings[user_ratings['binary_rating'] == 0]['movieId'].tolist()\n",
    "\n",
    "        sampled_liked_movies = np.random.choice(liked_movies, size=min(liked_movies_per_user, len(liked_movies)), replace=False).tolist()\n",
    "        sampled_disliked_movies = np.random.choice(disliked_movies, size=min(disliked_movies_per_user, len(disliked_movies)), replace=False).tolist()\n",
    "        \n",
    "        recommendations = recommender.get_content_based_recommendations(sampled_liked_movies, sampled_disliked_movies)\n",
    "        \n",
    "        true_positives = len(set(recommendations) & set(liked_movies))\n",
    "        false_positives = len(set(recommendations) - set(liked_movies))\n",
    "        false_negatives = len(set(sampled_liked_movies) - set(recommendations))\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "        \n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        user_metrics[user_id] = {'precision': precision, 'recall': recall, 'f1': f1}\n",
    "\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    \n",
    "    best_precision_user = max(user_metrics, key=lambda x: user_metrics[x]['precision'])\n",
    "    worst_precision_user = min(user_metrics, key=lambda x: user_metrics[x]['precision'])\n",
    "\n",
    "    best_recall_user = max(user_metrics, key=lambda x: user_metrics[x]['recall'])\n",
    "    worst_recall_user = min(user_metrics, key=lambda x: user_metrics[x]['recall'])\n",
    "\n",
    "    worst_f1_user = min(user_metrics, key=lambda x: user_metrics[x]['f1'])\n",
    "    best_f1_user = max(user_metrics, key=lambda x: user_metrics[x]['f1'])\n",
    "    \n",
    "    return mean_precision, mean_recall, mean_f1, user_metrics, best_precision_user, worst_precision_user, best_recall_user, worst_recall_user, worst_f1_user, best_f1_user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_ratings_count = ratings.groupby(['userId', 'binary_rating']).size().unstack(fill_value=0)\n",
    "eval_ratings_users = eval_ratings_count[(eval_ratings_count[1] >= 10) & (eval_ratings_count[0] >= 5)].index\n",
    "eval_ratings = ratings[ratings['userId'].isin(eval_ratings_users)]\n",
    "\n",
    "\n",
    "common_items = set(movies['id']).intersection(set(ratings['movieId']))\n",
    "eval_movies = movies[movies['id'].isin(common_items)]\n",
    "eval_ratings = eval_ratings[eval_ratings['movieId'].isin(common_items)]\n",
    "\n",
    "eval_movie_ids = eval_movies['id']\n",
    "eval_indices = np.where(np.isin(eval_movie_ids, eval_movie_ids))[0]\n",
    "eval_cosine_similarities = cosine_similarities[eval_indices][:, eval_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Precision: 0.031879543094496365\n",
      "Mean Recall: 0.028117346049589043\n",
      "Mean F1: 0.02973527240777459\n",
      "Best precision user: 73\n",
      "worst precision user: 2\n",
      "best recall user: 73\n",
      "worst recall user: 2\n",
      "best f1 user: 73\n",
      "worst f1 user: 2\n"
     ]
    }
   ],
   "source": [
    "content_based_recommender = ContentBasedRecommender(movie_ids=eval_movies['id'], cosine_similarities=eval_cosine_similarities)\n",
    "mean_precision, mean_recall, mean_f1, user_metrics, best_precision_user, worst_precision_user, best_recall_user, worst_recall_user, worst_f1_user, best_f1_user = evaluate_recommender(content_based_recommender, eval_ratings, liked_movies_per_user=10, disliked_movies_per_user=5, num_recommendations=5)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "print(\"Mean F1:\", mean_f1)\n",
    "print(\"Best precision user:\", best_precision_user)\n",
    "print(\"worst precision user:\", worst_precision_user)\n",
    "print(\"best recall user:\", best_recall_user)\n",
    "print(\"worst recall user:\", worst_recall_user)\n",
    "print(\"best f1 user:\", best_f1_user)\n",
    "print(\"worst f1 user:\", worst_f1_user)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for the best user (User ID: 73 ): {'precision': 0.6, 'recall': 0.375, 'f1': 0.4615384615384615}\n"
     ]
    }
   ],
   "source": [
    "sorted_user_metrics = sorted(user_metrics.items(), key=lambda x: x[1]['precision'], reverse=True)\n",
    "best_user_id, best_user_metrics = sorted_user_metrics[0]\n",
    "print(\"Metrics for the best user (User ID:\", best_user_id, \"):\", best_user_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dependencies/content_based_recommender.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(content_based_recommender, './dependencies/content_based_recommender.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, accuracy\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "class CollaborativeFilteringRecommender:\n",
    "    def __init__(self, ratings_df):\n",
    "        self.ratings_df = ratings_df\n",
    "        self.reader = Reader(rating_scale=(0, 1))\n",
    "        self.data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'binary_rating']], self.reader)\n",
    "        self.trainset, self.testset = train_test_split(self.data, test_size=0.2, random_state=42)\n",
    "        self.model = None\n",
    "        self.movie_mapping = None\n",
    "\n",
    "    def create_movie_mapping(self):\n",
    "        unique_movie_ids = self.ratings_df['movieId'].unique()\n",
    "\n",
    "        self.movie_mapping = pd.DataFrame({'movieId': unique_movie_ids, 'movie_column': range(len(unique_movie_ids))})\n",
    "\n",
    "        joblib.dump(self.movie_mapping, 'movie_mapping.joblib')\n",
    "\n",
    "    def tune_hyperparameters(self):\n",
    "        param_grid = {'n_epochs': [5, 15], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6], 'n_factors': [50, 100]}\n",
    "\n",
    "        svd = SVD()\n",
    "\n",
    "        grid_search = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae', 'fcp'], cv=5)\n",
    "\n",
    "        grid_search.fit(self.data)\n",
    "\n",
    "        best_params = grid_search.best_params\n",
    "        print(f'Best Parameters: {best_params}')\n",
    "\n",
    "    def train_model(self, hyperparameters=None):\n",
    "        if hyperparameters:\n",
    "            self.model = SVD(**hyperparameters)\n",
    "        else:\n",
    "            self.model = SVD()\n",
    "\n",
    "        self.model.fit(self.trainset)\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        predictions = self.model.test(self.testset)\n",
    "\n",
    "        rmse = accuracy.rmse(predictions)\n",
    "        mae = accuracy.mae(predictions)\n",
    "        mse = accuracy.mse(predictions)\n",
    "        fcp = accuracy.fcp(predictions)\n",
    "        \n",
    "    def recommend_for_user(self, user_id, n=10):\n",
    "        if self.movie_mapping is None:\n",
    "            self.create_movie_mapping()\n",
    "\n",
    "        all_movie_ids = self.ratings_df['movieId'].unique()\n",
    "\n",
    "        rated_movie_ids = self.ratings_df[self.ratings_df['userId'] == user_id]['movieId'].tolist()\n",
    "\n",
    "        unrated_movie_ids = list(set(all_movie_ids) - set(rated_movie_ids))\n",
    "\n",
    "        predictions = [self.model.predict(user_id, movie_id) for movie_id in unrated_movie_ids]\n",
    "\n",
    "        sorted_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)\n",
    "\n",
    "        top_n_recommendations = [prediction.iid for prediction in sorted_predictions[:n]]\n",
    "        \n",
    "        return top_n_recommendations\n",
    "\n",
    "collabRecommender = CollaborativeFilteringRecommender(ratings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'rmse': {'n_epochs': 15, 'lr_all': 0.005, 'reg_all': 0.4, 'n_factors': 50}, 'mae': {'n_epochs': 15, 'lr_all': 0.005, 'reg_all': 0.4, 'n_factors': 50}, 'fcp': {'n_epochs': 15, 'lr_all': 0.002, 'reg_all': 0.6, 'n_factors': 100}}\n"
     ]
    }
   ],
   "source": [
    "collabRecommender.tune_hyperparameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3558\n",
      "MAE:  0.2589\n",
      "MSE: 0.1266\n",
      "FCP:  0.6781\n",
      "[50, 1213, 44191, 1252, 2692, 68157, 1203, 1953, 908, 48516]\n"
     ]
    }
   ],
   "source": [
    "collabRecommender.train_model(hyperparameters={'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4, 'n_factors': 50})\n",
    "collabRecommender.evaluate_model()\n",
    "recommendations = collabRecommender.recommend_for_user(user_id=518, n=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dependencies/collaborative_filtering_model.joblib']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(collabRecommender, './dependencies/collaborative_filtering_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
